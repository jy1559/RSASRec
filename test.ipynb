{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jy1559/.conda/envs/first/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "환경 및 모듈 임포트 완료!\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: 환경 설정 및 필요한 라이브러리 import\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "\n",
    "# 재현성을 위한 random seed 설정\n",
    "seed = 20250318\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "\n",
    "# 패키지 구조에 맞게 모듈 import\n",
    "from Datasets.dataset import SeqRecDataset, seq_collate_fn, BucketBatchSampler\n",
    "from models.model import SeqRecModel\n",
    "from models.sub1_sequence_embedding import sentence_embed, sentence_embedder\n",
    "from models.sub2_time_gap import TimeGapEmbedding\n",
    "from models.sub3_attention import MultiHeadSelfAttention\n",
    "from models.sub4_user_embedding import UserEmbeddingUpdater\n",
    "from models.sub5_FFN import preprocess_inputs, create_ffn_model\n",
    "\n",
    "print(\"환경 및 모듈 임포트 완료!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "하이퍼파라미터 설정 완료!\n",
      "{'hf_model_path': 'sentence-transformers/all-MiniLM-L6-v2', 'embed_dim': 384, 'ffn_hidden_dim': 512, 'time_gap_hidden_dim': 128, 'num_attention_heads': 8, 'dropout': 0.2, 'strategy': 'EachSession_LastInter', 'update_flags': {'llm': True, 'tg': True, 'attention': True, 'ffn': True, 'user_emb': True, 'init_emb': True}, 'lora': {'use': True, 'r': 4, 'alpha': 32}, 'dataset_paths': {'interactions_path': './Datasets/Globo/interactions.json', 'item_metadata_path': './Datasets/Globo/item_metadata.json'}, 'batch_size': 2, 'use_bucket_batching': True}\n"
     ]
    }
   ],
   "source": [
    "# Cell 1.5: 테스트에 사용할 하이퍼파라미터 설정\n",
    "dataset_name = \"Globo\"\n",
    "hyperparams = {\n",
    "    # 모델 관련 하이퍼파라미터\n",
    "    \"hf_model_path\": \"sentence-transformers/all-MiniLM-L6-v2\",\n",
    "    \"embed_dim\": 384,\n",
    "    \"ffn_hidden_dim\": 512,\n",
    "    \"time_gap_hidden_dim\": 128,\n",
    "    \"num_attention_heads\": 8,\n",
    "    \"dropout\": 0.2,\n",
    "    \"strategy\": \"EachSession_LastInter\",\n",
    "    \"update_flags\": {\n",
    "         \"llm\": True,\n",
    "         \"tg\": True,\n",
    "         \"attention\": True,\n",
    "         \"ffn\": True,\n",
    "         \"user_emb\": True,\n",
    "         \"init_emb\": True\n",
    "    },\n",
    "    \"lora\": {\n",
    "         \"use\": True,\n",
    "         \"r\": 4,\n",
    "         \"alpha\": 32\n",
    "    },\n",
    "    # 데이터 경로 및 배치 사이즈\n",
    "    \"dataset_paths\": {\n",
    "         \"interactions_path\": f\"./Datasets/{dataset_name}/interactions.json\",\n",
    "         \"item_metadata_path\": f\"./Datasets/{dataset_name}/item_metadata.json\"\n",
    "    },\n",
    "    \"batch_size\": 2,  # 원하는 배치 사이즈로 변경 가능\n",
    "    \"use_bucket_batching\": True  # True이면 BucketBatchSampler 사용\n",
    "}\n",
    "\n",
    "print(\"하이퍼파라미터 설정 완료!\")\n",
    "print(hyperparams)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== DataLoader 배치 확인 ====\n",
      "item_id: torch.Size([2, 13, 4])\n",
      "embedding_sentences\n",
      "delta_ts: torch.Size([2, 13, 4])\n",
      "interaction_mask: torch.Size([2, 13, 4])\n",
      "session_mask: torch.Size([2, 13])\n",
      "Bucket Batch의 전체 padding 비율: 38.46%\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: 데이터셋 로드 및 DataLoader 구성 (hyperparams[\"use_bucket_batching\"]에 따라 결정)\n",
    "from torch.utils.data import DataLoader\n",
    "from Datasets.dataset import SeqRecDataset, seq_collate_fn, BucketBatchSampler\n",
    "\n",
    "# hyperparams에서 경로 가져오기\n",
    "interactions_path = hyperparams[\"dataset_paths\"][\"interactions_path\"]\n",
    "item_metadata_path = hyperparams[\"dataset_paths\"][\"item_metadata_path\"]\n",
    "\n",
    "dataset = SeqRecDataset(interactions_path, item_metadata_path)\n",
    "\n",
    "if hyperparams.get(\"use_bucket_batching\", False):\n",
    "    # BucketBatchSampler를 사용하여 DataLoader 구성\n",
    "    sampler = BucketBatchSampler(dataset, batch_size=hyperparams[\"batch_size\"], shuffle_batches=True)\n",
    "    dataloader = DataLoader(dataset, batch_sampler=sampler, collate_fn=seq_collate_fn)\n",
    "else:\n",
    "    # 기본 DataLoader 사용\n",
    "    dataloader = DataLoader(dataset, batch_size=hyperparams[\"batch_size\"], collate_fn=seq_collate_fn)\n",
    "\n",
    "# 첫 번째 배치 가져오기\n",
    "batch_data = next(iter(dataloader))\n",
    "\n",
    "# 배치 딕셔너리의 각 key와 텐서 shape 확인\n",
    "print(\"==== DataLoader 배치 확인 ====\")\n",
    "for key, value in batch_data.items():\n",
    "    if torch.is_tensor(value):\n",
    "        print(f\"{key}: {value.shape}\")\n",
    "    else:\n",
    "        print(f\"{key}\")#: {value}\")\n",
    "\n",
    "# bucket batching을 사용한 경우, padding 비율 확인 (-1이 padding으로 사용됨)\n",
    "if hyperparams.get(\"use_bucket_batching\", False):\n",
    "    item_ids = batch_data['item_id']  # [B, S, I] 텐서\n",
    "    padding_ratio = (item_ids == -1).float().mean().item()\n",
    "    print(\"Bucket Batch의 전체 padding 비율: {:.2%}\".format(padding_ratio))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문장 임베딩 출력 shape: torch.Size([2, 13, 4, 384])\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: 문장 임베딩 테스트\n",
    "tokenizer, sentence_model = sentence_embedder(hyperparams[\"hf_model_path\"])\n",
    "sentences = batch_data['embedding_sentences']\n",
    "interaction_mask = batch_data['interaction_mask']  # [B, S, I] 텐서\n",
    "\n",
    "embeddings = sentence_embed(tokenizer, sentence_model, sentences, interaction_mask)\n",
    "print(\"문장 임베딩 출력 shape:\", embeddings.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "시간 간격 임베딩 출력 shape: torch.Size([2, 13, 4, 384])\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: 시간 간격 임베딩 테스트\n",
    "delta_ts = batch_data['delta_ts']\n",
    "time_gap_embedder = TimeGapEmbedding(\n",
    "    embedding_dim=hyperparams[\"embed_dim\"],\n",
    "    hidden_dim=hyperparams[\"time_gap_hidden_dim\"]\n",
    ")\n",
    "time_gap_embeddings = time_gap_embedder(delta_ts)\n",
    "print(\"시간 간격 임베딩 출력 shape:\", time_gap_embeddings.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention 출력 shape: torch.Size([2, 13, 4, 384])\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: MultiHeadSelfAttention 테스트\n",
    "combined_emb = embeddings + time_gap_embeddings  # [B, S, I, D]\n",
    "attention_mask = interaction_mask\n",
    "\n",
    "attention_module = MultiHeadSelfAttention(\n",
    "    embedding_dim=hyperparams[\"embed_dim\"],\n",
    "    num_heads=hyperparams[\"num_attention_heads\"],\n",
    "    dropout=hyperparams[\"dropout\"]\n",
    ")\n",
    "attention_out = attention_module(combined_emb, attention_mask)\n",
    "print(\"Attention 출력 shape:\", attention_out.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "업데이트된 사용자 임베딩 shape: torch.Size([2, 384])\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: UserEmbeddingUpdater 테스트\n",
    "user_updater = UserEmbeddingUpdater(embedding_dim=hyperparams[\"embed_dim\"])\n",
    "session_mask = batch_data['session_mask']\n",
    "\n",
    "updated_user_emb = user_updater(attention_out, interaction_mask, session_mask)\n",
    "print(\"업데이트된 사용자 임베딩 shape:\", updated_user_emb.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 13, 4, 384])\n",
      "torch.Size([2, 13, 4, 384])\n",
      "torch.Size([2, 1, 1, 384])\n",
      "FFN 입력 shape: torch.Size([2, 13, 4, 384])\n",
      "FFN 출력 shape: torch.Size([2, 13, 4, 384])\n"
     ]
    }
   ],
   "source": [
    "# Cell 7: FFN 테스트\n",
    "ffn_input = preprocess_inputs(attention_out, time_gap_embeddings, updated_user_emb)\n",
    "print(\"FFN 입력 shape:\", ffn_input.shape)\n",
    "\n",
    "ffn_model = create_ffn_model(\n",
    "    input_dim=ffn_input.shape[-1],\n",
    "    hidden_dim=hyperparams[\"ffn_hidden_dim\"],\n",
    "    output_dim=ffn_input.shape[-1]\n",
    ")\n",
    "ffn_out = ffn_model(ffn_input)\n",
    "print(\"FFN 출력 shape:\", ffn_out.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 13, 4, 384])\n",
      "torch.Size([2, 13, 4, 384])\n",
      "torch.Size([2, 1, 1, 384])\n",
      "모델 출력 feature shape: torch.Size([2, 13, 384])\n",
      "업데이트된 사용자 임베딩 shape: torch.Size([2, 384])\n"
     ]
    }
   ],
   "source": [
    "# Cell 8: 전체 모델 (SeqRecModel) 단일 배치 forward 테스트\n",
    "model = SeqRecModel(\n",
    "    embed_dim=hyperparams[\"embed_dim\"],\n",
    "    strategy=hyperparams[\"strategy\"],\n",
    "    update=hyperparams[\"update_flags\"],\n",
    "    lora=hyperparams[\"lora\"],\n",
    "    ffn_hidden_dim=hyperparams[\"ffn_hidden_dim\"],\n",
    "    time_gap_hidden_dim=hyperparams[\"time_gap_hidden_dim\"],\n",
    "    num_attention_heads=hyperparams[\"num_attention_heads\"],\n",
    "    dropout=hyperparams[\"dropout\"],\n",
    "    hf_model_path=hyperparams[\"hf_model_path\"]\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    output_features, new_user_emb = model(batch_data)\n",
    "\n",
    "print(\"모델 출력 feature shape:\", output_features.shape)\n",
    "print(\"업데이트된 사용자 임베딩 shape:\", new_user_emb.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== 최종 확인 ====\n",
      "문장 임베딩: torch.Size([2, 13, 4, 384])\n",
      "시간 간격 임베딩: torch.Size([2, 13, 4, 384])\n",
      "Attention 출력: torch.Size([2, 13, 4, 384])\n",
      "FFN 출력: torch.Size([2, 13, 4, 384])\n",
      "모델 최종 출력 feature: torch.Size([2, 13, 384])\n",
      "최종 사용자 임베딩: torch.Size([2, 384])\n"
     ]
    }
   ],
   "source": [
    "# Cell 9: 전체 결과 정리\n",
    "print(\"==== 최종 확인 ====\")\n",
    "print(\"문장 임베딩:\", embeddings.shape)\n",
    "print(\"시간 간격 임베딩:\", time_gap_embeddings.shape)\n",
    "print(\"Attention 출력:\", attention_out.shape)\n",
    "print(\"FFN 출력:\", ffn_out.shape)\n",
    "print(\"모델 최종 출력 feature:\", output_features.shape)\n",
    "print(\"최종 사용자 임베딩:\", new_user_emb.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== 최종 확인 ====\n",
      "문장 임베딩: torch.Size([2, 13, 4, 384])\n",
      "시간 간격 임베딩: torch.Size([2, 13, 4, 384])\n",
      "Attention 출력: torch.Size([2, 13, 4, 384])\n",
      "FFN 출력: torch.Size([2, 13, 4, 384])\n",
      "모델 최종 출력 feature: torch.Size([2, 13, 384])\n",
      "최종 사용자 임베딩: torch.Size([2, 384])\n"
     ]
    }
   ],
   "source": [
    "# Cell 10: 각 모듈별 출력 shape 및 결과 정리\n",
    "print(\"==== 최종 확인 ====\")\n",
    "print(\"문장 임베딩:\", embeddings.shape)\n",
    "print(\"시간 간격 임베딩:\", time_gap_embeddings.shape)\n",
    "print(\"Attention 출력:\", attention_out.shape)\n",
    "print(\"FFN 출력:\", ffn_out.shape)\n",
    "print(\"모델 최종 출력 feature:\", output_features.shape)\n",
    "print(\"최종 사용자 임베딩:\", new_user_emb.shape)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
