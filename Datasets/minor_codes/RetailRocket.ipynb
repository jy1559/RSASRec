{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 rows of beyms.csv:\n",
      "   user_id\n",
      "0  1049656\n",
      "1  1055118\n",
      "2  1056935\n",
      "3  1070023\n",
      "4  1072752 \n",
      "\n",
      "First 5 rows of events.csv:\n",
      "    user_id  artist_id  album_id  track_id   timestamp\n",
      "0  31435741         21        31        53  1370977938\n",
      "1  31435741         21        31        53  1370977728\n",
      "2  31435741         21        31        53  1370977518\n",
      "3  31435741         21        31        53  1370977308\n",
      "4  31435741         21        31        53  1370977098 \n",
      "\n",
      "First 5 rows of genre_annotations.csv:\n",
      "   Unnamed: 0  track_id                                             genres\n",
      "0           1      4868  ['soul', 'pop', 'singersongwriter', 'blues', '...\n",
      "1           2      2900  ['electronic', 'indiepop', 'shoegaze', 'dreamp...\n",
      "2           5    572665  ['soul', 'pop', 'singersongwriter', 'blues', '...\n",
      "3           6      2897  ['indierock', 'electronic', 'indiepop', 'postp...\n",
      "4           7     15100  ['folk', 'indiefolk', 'banjo', 'folkrock', 'bl... \n",
      "\n",
      "First 5 rows of mainstreaminess.csv:\n",
      "   Unnamed: 0   user_id  M_global_R_APC\n",
      "0           0   6823936        0.232189\n",
      "1           5  23937043        0.288424\n",
      "2           9   8259615        0.098305\n",
      "3          15   4030517        0.241614\n",
      "4          16   4933688       -0.026237 \n",
      "\n",
      "First 5 rows of ms.csv:\n",
      "    user_id\n",
      "0  50900118\n",
      "1  43009758\n",
      "2  13959381\n",
      "3  12531653\n",
      "4  40351516 \n",
      "\n",
      "First 5 rows of user_groups.csv:\n",
      "   user_id  user group\n",
      "0  1049656           2\n",
      "1  1055118           1\n",
      "2  1056935           1\n",
      "3  1070023           1\n",
      "4  1072752           0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "    \n",
    "datasets = {\"Retail_Rocket\": {\"path\": '/home/jy1559/Mar2025_Module/Datasets/Retail_Rocket',\n",
    "                              \"file_names\": ['category_tree.csv', 'events.csv', 'item_properties_part1.csv', 'item_properties_part2.csv']},\n",
    "            \"Diginetica\": {\"path\": '/home/jy1559/Mar2025_Module/Datasets/Diginetica',\n",
    "                              \"file_names\": ['product-categories.csv', 'products.csv', 'train-clicks.csv', 'train-item-views.csv', 'train-purchases.csv', 'train-queries.csv']},\n",
    "            \"LFM-BeyMS\": {\"path\": '/home/jy1559/Mar2025_Module/Datasets/LFM-BeyMS/dataset',\n",
    "                              \"file_names\": ['beyms.csv', 'events.csv', 'genre_annotations.csv', 'mainstreaminess.csv', 'ms.csv', 'user_groups.csv']},\n",
    "            \"Beauty\": {\"path\": '/home/jy1559/Mar2025_Module/Datasets/Amazon',\n",
    "                \"file_names\": ['All_Beauty.jsonl', 'meta_All_Beauty.jsonl']},\n",
    "            \"Game\": {\"path\": '/home/jy1559/Mar2025_Module/Datasets/Amazon',\n",
    "                \"file_names\": ['Video_Games.jsonl', 'meta_Video_Games.jsonl']}}\n",
    "dataset = datasets[\"LFM-BeyMS\"]\n",
    "directory_path = dataset['path']\n",
    "file_names = dataset[\"file_names\"]\n",
    "for name in file_names:\n",
    "    file_path = os.path.join(directory_path, name)\n",
    "    try:\n",
    "        if 'csv' in file_path:\n",
    "            df = pd.read_csv(file_path)\n",
    "        elif 'json' in file_path:\n",
    "            df = pd.read_json(file_path, lines=True)\n",
    "        print(f\"First 5 rows of {name}:\")\n",
    "        print(df.head(), \"\\n\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File {name} not found in the directory {directory_path}.\")\n",
    "    except pd.errors.EmptyDataError:\n",
    "        print(f\"File {name} is empty.\")\n",
    "    except pd.errors.ParserError:\n",
    "        print(f\"Error parsing {name}. Please check the file for inconsistencies.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASIN: B076WQZGPM\n",
      "Sentence: Title: Yes to Tomatoes Detoxifying Charcoal Cleanser (Pack of 2) with Charcoal Powder, Tomato Fruit Extract, and Gingko Biloba Leaf Extract, 5 fl. oz.. Average rating: 4.5, based on 3 reviews. Store: Yes To. Details: Item Form: Powder, Skin Type: Acne Prone, Brand: Yes To, Age Range (Description): Adult, Unit Count: 10 Fl Oz, Is Discontinued By Manufacturer: No, Item model number: SG_B076WQZGPM_US, UPC: 653801351125, Manufacturer: Yes to Tomatoes.\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "\n",
    "def safe_eval(val, expected_type):\n",
    "    \"\"\"\n",
    "    문자열 형태의 리스트나 딕셔너리를 안전하게 평가하고, \n",
    "    만약 평가에 실패하거나 타입이 맞지 않으면 빈 값을 반환합니다.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        evaluated = ast.literal_eval(val) if isinstance(val, str) else val\n",
    "        if isinstance(evaluated, expected_type):\n",
    "            return evaluated\n",
    "    except Exception:\n",
    "        pass\n",
    "    return None\n",
    "\n",
    "def construct_item_sentence(row):\n",
    "    parts = []\n",
    "    \n",
    "    # Title\n",
    "    title = row.get('title', '').strip()\n",
    "    if title:\n",
    "        parts.append(f\"Title: {title}.\")\n",
    "    \n",
    "    # Rating 정보\n",
    "    avg_rating = row.get('average_rating')\n",
    "    rating_number = row.get('rating_number')\n",
    "    if avg_rating is not None and rating_number is not None:\n",
    "        parts.append(f\"Average rating: {avg_rating}, based on {rating_number} reviews.\")\n",
    "    \n",
    "    # Features (리스트 형태)\n",
    "    features = safe_eval(row.get('features', ''), list)\n",
    "    if features:\n",
    "        # 리스트가 비어있지 않으면 각 항목을 문자열로 연결\n",
    "        features_text = \", \".join(str(f).strip() for f in features if f)\n",
    "        if features_text:\n",
    "            parts.append(f\"Features: {features_text}.\")\n",
    "    \n",
    "    # Description (리스트 형태)\n",
    "    description = safe_eval(row.get('description', ''), list)\n",
    "    if description:\n",
    "        description_text = \" \".join(str(d).strip() for d in description if d)\n",
    "        if description_text:\n",
    "            parts.append(f\"Description: {description_text}.\")\n",
    "    \n",
    "    # Store (문자열)\n",
    "    store = row.get('store', '')\n",
    "    if store:\n",
    "        parts.append(f\"Store: {store.strip()}.\")\n",
    "    \n",
    "    # Details (딕셔너리 형태)\n",
    "    details = safe_eval(row.get('details', ''), dict)\n",
    "    if details:\n",
    "        # key: value 형태로 변환\n",
    "        details_text = \", \".join(f\"{k}: {v}\" for k, v in details.items() if v)\n",
    "        if details_text:\n",
    "            parts.append(f\"Details: {details_text}.\")\n",
    "    \n",
    "    # 모든 부분을 하나의 문장으로 합치기\n",
    "    return \" \".join(parts)\n",
    "\n",
    "# 예시: df는 amazon metadata가 담긴 DataFrame\n",
    "# parent_asin을 key로 하는 dictionary 생성\n",
    "file_path = os.path.join(directory_path, dataset[\"file_names\"][2])\n",
    "item_sentences = {}\n",
    "for idx, row in df.iterrows():\n",
    "    asin = row.get('parent_asin', None)\n",
    "    if asin:\n",
    "        sentence = construct_item_sentence(row)\n",
    "        item_sentences[asin] = sentence\n",
    "\n",
    "# 결과 확인: 특정 아이템의 문장을 출력\n",
    "example_asin = list(item_sentences.keys())[1]\n",
    "print(f\"ASIN: {example_asin}\\nSentence: {item_sentences[example_asin]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jy1559/.conda/envs/first/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      " 17%|█▋        | 105142/631986 [00:36<02:48, 3131.40it/s]"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "file_path = os.path.join(directory_path, dataset[\"file_names\"][0])\n",
    "df = pd.read_json(file_path, lines=True)\n",
    "# 1. 타임스탬프를 자연어 형태로 변환 (연-월-일 시:분:초)\n",
    "df['datetime'] = pd.to_datetime(df['timestamp'], unit='ms')\n",
    "df['datetime_str'] = df['datetime'].dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "# 날짜만 추출해서 그룹핑용으로 사용 (연-월-일)\n",
    "df['date'] = df['datetime'].dt.date\n",
    "\n",
    "# 2. 필요한 컬럼만 선택하여 리뷰 정보를 딕셔너리 형태로 정리\n",
    "def get_review_info(row):\n",
    "    return {\n",
    "        \"parent_asin\": row['parent_asin'],\n",
    "        \"asin\": row['asin'],\n",
    "        \"timestamp\": row['datetime_str'],\n",
    "        \"review_info\": {\n",
    "        \"rating\": row['rating'],\n",
    "        \"title\": row['title'],\n",
    "        \"text\": row['text'],\n",
    "        \"helpful_vote\": row['helpful_vote']}\n",
    "    }\n",
    "\n",
    "df['review_info'] = df.apply(get_review_info, axis=1)\n",
    "\n",
    "# 3. user_id별로 그룹화한 뒤, 같은 날짜별로 리뷰 그룹을 생성\n",
    "# 결과: { user_id: [ [review1, review2, ...] (같은 날), [review3, ...], ... ] }\n",
    "user_groups = {}\n",
    "for user, group in tqdm(df.groupby('user_id')):\n",
    "    # 날짜별 그룹 (리스트 순서는 날짜 오름차순)\n",
    "    day_groups = []\n",
    "    for date, day_df in group.groupby('date'):\n",
    "        # 해당 날짜에 해당하는 리뷰 정보 리스트\n",
    "        reviews = day_df['review_info'].tolist()\n",
    "        day_groups.append(reviews)\n",
    "    user_groups[user] = day_groups\n",
    "\n",
    "# 만약 user_id를 제거하고, 모든 사용자의 데이터만 리스트로 저장하려면:\n",
    "all_users_data = list(user_groups.values())\n",
    "import pandas as pd\n",
    "\n",
    "# 파일 경로 (각 경로는 실제 경로에 맞게 수정)\n",
    "events_path = '/path/to/events.csv'\n",
    "genres_path = '/path/to/genre_annotations.csv'\n",
    "beyms_path = '/path/to/beyms.csv'\n",
    "\n",
    "# CSV 파일 로드\n",
    "df_events = pd.read_csv(events_path)\n",
    "df_genres = pd.read_csv(genres_path)\n",
    "df_beyms = pd.read_csv(beyms_path)\n",
    "\n",
    "# 1. 타임스탬프 변환\n",
    "# events.csv의 timestamp가 초 단위라고 가정 (예: 1370977938)\n",
    "df_events['datetime'] = pd.to_datetime(df_events['timestamp'], unit='s')\n",
    "df_events['datetime_str'] = df_events['datetime'].dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "df_events['date'] = df_events['datetime'].dt.date  # 그룹화용 날짜 정보\n",
    "\n",
    "# 2. genre_annotations와 병합 (track_id 기준)\n",
    "# genre_annotations.csv에서 필요한 컬럼만 사용 (여기서는 'track_id'와 'genres')\n",
    "df_events = df_events.merge(df_genres[['track_id', 'genres']], on='track_id', how='left')\n",
    "\n",
    "# 3. beyms.csv에 있는 사용자만 필터링 (관심 사용자)\n",
    "beyms_user_ids = set(df_beyms['user_id'].unique())\n",
    "df_events = df_events[df_events['user_id'].isin(beyms_user_ids)]\n",
    "\n",
    "# 4. user_id별, 그리고 같은 날짜(연-월-일)별로 그룹화하여 세션 구성\n",
    "user_sessions = {}import pandas as pd\n",
    "\n",
    "# 파일 경로 (각 경로는 실제 경로에 맞게 수정)\n",
    "events_path = '/path/to/events.csv'\n",
    "genres_path = '/path/to/genre_annotations.csv'\n",
    "beyms_path = '/path/to/beyms.csv'\n",
    "\n",
    "# CSV 파일 로드\n",
    "df_events = pd.read_csv(events_path)\n",
    "df_genres = pd.read_csv(genres_path)\n",
    "df_beyms = pd.read_csv(beyms_path)\n",
    "\n",
    "# 1. 타임스탬프 변환\n",
    "# events.csv의 timestamp가 초 단위라고 가정 (예: 1370977938)\n",
    "df_events['datetime'] = pd.to_datetime(df_events['timestamp'], unit='s')\n",
    "df_events['datetime_str'] = df_events['datetime'].dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "df_events['date'] = df_events['datetime'].dt.date  # 그룹화용 날짜 정보\n",
    "\n",
    "# 2. genre_annotations와 병합 (track_id 기준)\n",
    "# genre_annotations.csv에서 필요한 컬럼만 사용 (여기서는 'track_id'와 'genres')\n",
    "df_events = df_events.merge(df_genres[['track_id', 'genres']], on='track_id', how='left')\n",
    "\n",
    "# 3. beyms.csv에 있는 사용자만 필터링 (관심 사용자)\n",
    "beyms_user_ids = set(df_beyms['user_id'].unique())\n",
    "df_events = df_events[df_events['user_id'].isin(beyms_user_ids)]\n",
    "\n",
    "# 4. user_id별, 그리고 같은 날짜(연-월-일)별로 그룹화하여 세션 구성\n",
    "user_sessions = {}\n",
    "for user_id, user_group in df_events.groupby('user_id'):\n",
    "    sessions = []\n",
    "    for date, day_group in user_group.groupby('date'):\n",
    "        events_list = []\n",
    "        for idx, row in day_group.iterrows():\n",
    "            event = {\n",
    "                \"artist_id\": row[\"artist_id\"],\n",
    "                \"album_id\": row[\"album_id\"],\n",
    "                \"track_id\": row[\"track_id\"],\n",
    "                \"datetime\": row[\"datetime_str\"],\n",
    "                \"genres\": row[\"genres\"] if pd.notna(row[\"genres\"]) else \"\"\n",
    "            }\n",
    "            events_list.append(event)\n",
    "        sessions.append(events_list)\n",
    "    user_sessions[user_id] = sessions\n",
    "\n",
    "# 예시: 첫 번째 사용자에 대한 세션 출력 (user_id는 key로 남아있음)\n",
    "example_user = list(user_sessions.keys())[0]\n",
    "print(f\"User {example_user} sessions:\")\n",
    "for i, session in enumerate(user_sessions[example_user], 1):\n",
    "    print(f\"  Session {i}:\")\n",
    "    for event in session:\n",
    "        print(\"    \", event)\n",
    "        \n",
    "# 만약 user_id를 제거하고 단순히 모든 사용자의 세션 리스트가 필요하다면:\n",
    "all_user_sessions = list(user_sessions.values())\n",
    "\n",
    "for user_id, user_group in df_events.groupby('user_id'):\n",
    "    sessions = []\n",
    "    for date, day_group in user_group.groupby('date'):\n",
    "        events_list = []\n",
    "        for idx, row in day_group.iterrows():\n",
    "            event = {\n",
    "                \"artist_id\": row[\"artist_id\"],\n",
    "                \"album_id\": row[\"album_id\"],\n",
    "                \"track_id\": row[\"track_id\"],\n",
    "                \"datetime\": row[\"datetime_str\"],\n",
    "                \"genres\": row[\"genres\"] if pd.notnaimport pandas as pd\n",
    "\n",
    "# 파일 경로 (각 경로는 실제 경로에 맞게 수정)\n",
    "events_path = '/path/to/events.csv'\n",
    "genres_path = '/path/to/genre_annotations.csv'\n",
    "beyms_path = '/path/to/beyms.csv'\n",
    "\n",
    "# CSV 파일 로드\n",
    "df_events = pd.read_csv(events_path)\n",
    "df_genres = pd.read_csv(genres_path)\n",
    "df_beyms = pd.read_csv(beyms_path)\n",
    "\n",
    "# 1. 타임스탬프 변환\n",
    "# events.csv의 timestamp가 초 단위라고 가정 (예: 1370977938)\n",
    "df_events['datetime'] = pd.to_datetime(df_events['timestamp'], unit='s')\n",
    "df_events['datetime_str'] = df_events['datetime'].dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "df_events['date'] = df_events['datetime'].dt.date  # 그룹화용 날짜 정보\n",
    "\n",
    "# 2. genre_annotations와 병합 (track_id 기준)\n",
    "# genre_annotations.csv에서 필요한 컬럼만 사용 (여기서는 'track_id'와 'genres')\n",
    "df_events = df_events.merge(df_genres[['track_id', 'genres']], on='track_id', how='left')\n",
    "\n",
    "# 3. beyms.csv에 있는 사용자만 필터링 (관심 사용자)\n",
    "beyms_user_ids = set(df_beyms['user_id'].unique())\n",
    "df_events = df_events[df_events['user_id'].isin(beyms_user_ids)]\n",
    "\n",
    "# 4. user_id별, 그리고 같은 날짜(연-월-일)별로 그룹화하여 세션 구성\n",
    "user_sessions = {}\n",
    "for user_id, user_group in df_events.groupby('user_id'):\n",
    "    sessions = []\n",
    "    for date, day_group in user_group.groupby('date'):\n",
    "        events_list = []\n",
    "        for idx, row in day_group.iterrows():\n",
    "            event = {\n",
    "                \"artist_id\": row[\"artist_id\"],\n",
    "                \"album_id\": row[\"album_id\"],\n",
    "                \"track_id\": row[\"track_id\"],\n",
    "                \"datetime\": row[\"datetime_str\"],\n",
    "                \"genres\": row[\"genres\"] if pd.notna(row[\"genres\"]) else \"\"\n",
    "            }\n",
    "            events_list.append(event)\n",
    "        sessions.append(events_list)\n",
    "    user_sessions[user_id] = sessions\n",
    "\n",
    "# 예시: 첫 번째 사용자에 대한 세션 출력 (user_id는 key로 남아있음)\n",
    "example_user = list(user_sessions.keys())[0]\n",
    "print(f\"User {example_user} sessions:\")\n",
    "for i, session in enumerate(user_sessions[example_user], 1):\n",
    "    print(f\"  Session {i}:\")\n",
    "    for event in session:\n",
    "        print(\"    \", event)\n",
    "        \n",
    "# 만약 user_id를 제거하고 단순히 모든 사용자의 세션 리스트가 필요하다면:\n",
    "all_user_sessions = list(user_sessions.values())\n",
    "(row[\"genres\"]) else \"\"\n",
    "            }\n",
    "            events_list.append(event)\n",
    "        sessions.append(events_list)\n",
    "    user_sessions[user_id] = sessions\n",
    "\n",
    "# 예시: 첫 번째 사용자에 대한 세션 출력 (user_id는 key로 남아있음)\n",
    "example_user = list(user_sessions.keys())[0]\n",
    "print(f\"User {example_user} sessions:\")\n",
    "for i, session in enumerate(user_sessions[example_user], 1):\n",
    "    print(f\"  Session {i}:\")\n",
    "    for event in session:\n",
    "        print(\"    \", event)\n",
    "        \n",
    "# 만약 user_id를 제거하고 단순히 모든 사용자의 세션 리스트가 필요하다면:\n",
    "all_user_sessions = list(user_sessions.values())\n",
    "\n",
    "# 결과 예시 출력 (첫 번째 user의 데이터를 출력)\n",
    "example_user = list(user_groups.keys())[0]\n",
    "print(f\"User {example_user} grouped reviews:\")\n",
    "for i, day_group in enumerate(user_groups[example_user], 2):\n",
    "    print(f\"  Day group {i}:\")\n",
    "    for review in day_group:\n",
    "        print(\"   \", review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'user_groups' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m example_user \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[43muser_groups\u001b[49m\u001b[38;5;241m.\u001b[39mkeys())[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(user_groups[example_user])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'user_groups' is not defined"
     ]
    }
   ],
   "source": [
    "example_user = list(user_groups.keys())[0]\n",
    "print(user_groups[example_user])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
